An end-to-end Retrieval-Augmented Generation (RAG) system that allows authenticated users to upload documents and chat with their content using a Large Language Model. The application supports PDF, DOCX, and TXT uploads, performs chunking and embedding, stores vectors in a vector database, and retrieves relevant context at query time to generate accurate, source-aware responses. It features secure user authentication with Supabase, user-scoped document storage, persistent conversation memory, and real-time streaming responses via FastAPI. The system is built with Python, FastAPI, FAISS/Chroma, LLaMA (via Groq API), and a React frontend, and is fully deployed to production, demonstrating real-world AI system design beyond simple LLM API usage.
